{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征缩放\n",
    "特征缩放是用来统一资料中的自变项或特征范围的方法. 数据标准化就是特征缩放的一种.\n",
    "\n",
    "特征缩放将数据集中各特征的缩放尺度标准化, 如特征A缩放尺度为千(即变化幅度多以千为单位), 特征B缩放尺度为十,\n",
    "标准化后, 缩放范围都为 `[-1,1]`.\n",
    "\n",
    "特征缩放后, 多维特征将具有相近的相似度, 对于 梯度下降/线性回归 等算法, 有助于提升收敛速度.\n",
    "\n",
    "具体可参考 [为什么要对特征进行缩放](https://zhuanlan.zhihu.com/p/25234554), 源自\n",
    "[梯度下降_Andrew Ng的机器学习课程](https://www.coursera.org/lecture/machine-learning/gradient-descent-in-practice-i-feature-scaling-xx3Da)\n",
    "\n",
    "## 数据标准化\n",
    "数据的标准化(normalization)是将数据按比例缩放, 使之落入一个小的特定区间. 去除数据的单位限制, 将其转化为无量纲的纯数值, 便于不同单位或量级的指标能够进行比较和加权.\n",
    "\n",
    "常用的标准化方法有\n",
    "1. 归一化: 将数据映射到 `[0,1]` 区间. 常见的归一化方法有\n",
    "    - 离差标准化: 对原始数据的线性变换, 使结果落到 `[0,1]` 区间. 公式参考网络\n",
    "2. 标准差标准化(Z标准化): 经过处理的数据符合标准正态分布, 即均值为0, 标准差为1.\n",
    "\n",
    "## 数据中心化\n",
    "数据中心化, 又称零均值化, 数据集经处理后, 各特征的平均值为0, 对标准差无要求.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用的指标\n",
    "1. 调和平均数, 又称倒数平均数, 是总体各统计变量倒数的算术平均数的倒数. (求水流速度/并联电阻总电阻皆是该方法.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "- [数据标准化、归一化、中心化处理](https://zhuanlan.zhihu.com/p/33727799)\n",
    "- [为什么要对特征进行缩放](https://zhuanlan.zhihu.com/p/25234554)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
