{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "官方API文档 [API DOC](https://pandas.pydata.org/pandas-docs/stable/reference/index.html)\n",
    "\n",
    "Pandas 的核心类是 DataFrame 和 Series.\n",
    "\n",
    "## 术语\n",
    "- scalar: 标量, 即常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本使用\n",
    "### 创建数据\n",
    "pandas 直接使用相关类的构造函数创建. pyspark 使用函数创建 DataFrame\n",
    "\n",
    "Series\n",
    "- 构造函数: `pandas.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)`\n",
    "  - data: array-like, Iterable, dict, or scalar value\n",
    "\n",
    "Index 索引\n",
    "- 时间索引: `date_range()`, 按照时间生成序列.\n",
    "  - 签名: `date_range(start=None, end=None, periods=None, freq=None, tz=None, normalize=False, name=None, closed=None, **kwargs)`\n",
    "    - start/end 开始/结束时间\n",
    "    - periods 要生成的时间长度\n",
    "    - freq 时间单位. D天 S秒 H小时 等等. 参考 [Date Offset aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "\n",
    "DataFrame\n",
    "- 构造函数: `DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)`\n",
    "  - data: ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
    "- 从文件中读取\n",
    "  - 从 csv 读取: `pd.read_csv(path,sep=',')`. [API](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手动指定\n",
    "df = pd.DataFrame({'a':[1,2,3], 'b':[1,2,3], 'c':[1,2,3]})\n",
    "print(df)\n",
    "\n",
    "# 通过 numpy 创建\n",
    "df = pd.DataFrame(np.arange(16).reshape((4,4)),index=[\"a\",\"b\",\"c\",\"d\"],columns=[\"a\",\"b\",\"c\",\"d\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理\n",
    "- `df.apply()`, 对轴上的每个数据进行自定义处理\n",
    "  - 签名: `df.apply(self, func, axis=0, broadcast=None, raw=False, reduce=None, result_type=None, args=(), **kwds)`\n",
    "    - func: apply to each column or row. 处理 指定轴的每一行数据. \n",
    "    - axis: index(0) or column(1), default 0\n",
    "    \n",
    "- `df.applymap()`, 对 dataframe 的每个元素进行处理. 与 apply 不同的是, applymap 每次传入函数的是每个元素, apply 每次传入函数的是每行数据.\n",
    "  - 签名: `df.applymap(self, func)`\n",
    "\n",
    "- `df.shift()`, dataframe 移位操作\n",
    "  - 签名: `df.shift(self, periods=1, freq=None, axis=0, fill_value=None)`\n",
    "    - periods: 移位位数.\n",
    "    - axis: 移位方向. 惯例, index(0) or column(1)\n",
    "    - freq: 当行索引为时间序列时使用, freq 决定时间索引 移位的频率, `freq*periods` 决定时间索引的偏移值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "print(df)\n",
    "\n",
    "# 对每一列进行 sum, 使用脚标取值\n",
    "def sum(nums):\n",
    "    result = 0\n",
    "    for num in nums:\n",
    "        result+=num\n",
    "    return result\n",
    "\n",
    "df = df.apply(sum)\n",
    "print(df)\n",
    "\n",
    "# 使用 lambda 取值\n",
    "df = df.apply(lambda x: x+1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选行/列\n",
    "行筛选方法如下\n",
    "- `df.loc[]` : 按照 key 值筛选, 即 location, 可以使用掩码形式, 如\"2014-06\"可以代表六月所有行(需要该列为date类型). 示例如下\n",
    "  - `df.loc['20130101',..]` 只选 `key==20130101` 的行(一行)\n",
    "  - `df.loc['20130101':'20130102',..]` 选则 `20130101<= key <=20130102` 的行, 包括两端\n",
    "  - `df.loc[:,..]` 选择全部行\n",
    "- `df.iloc[]`: 按照 索引 值筛选. iloc 即 index location\n",
    "  - `df.iloc[0,..]` 与正常的切片方式相同, 选择 `index==0` 行\n",
    "  - `df.iloc[0:1,..]` 与正常的切片方式相同, 选择 `[0,1)`. (左闭右开)\n",
    "  - `df.iloc[[0,1,3],..]` 选择 index 为 0,1,3 的行\n",
    "- 布尔值筛选, 对每一列筛选\n",
    "  - `df[df.A > 0]` 选择列A 值大于0的行\n",
    "  - `df[df>0]=-df` 将df中所有值大于0的元素取负\n",
    "    - `-df` 全部值取负.\n",
    "  - `df[df['A'].isin(['two','four'])]` 列A值为 two 或 four 的行\n",
    "- 其他\n",
    "  - `pd.isna(df)`: 返回df是否有值的 布尔掩码\n",
    "\n",
    "列筛选与行筛选类似, 只是使用 loc 的第二个参数. 如 `df.iloc[0:1, 1:2]`: 0:1 表示筛选的行, 1:2 表示取的列. 其他不再详述\n",
    "注意, 取行时默认选择取全部列, 所以第二个参数可以不填. \n",
    "取列时没有默认值, 所以必须选择行. 否则会报错.\n",
    "\n",
    "pyspark 中取行列与pandas不同, pyspark 主要用sql方式取. 示例如下\n",
    "- 注册临时表, 执行sql. `df.registerTempTable('tmp_df')`, 而后执行相应sql `df2=spark.sql('sql')` 即可\n",
    "- 使用pyspark api: `df.select('field1', 'field2').orderBy(df.field3.asc).limit()`\n",
    "- 导出dataframe然后处理. 如 `df.toPandas()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(15).reshape((3,5)) )\n",
    "print(df)\n",
    "\n",
    "# loc取行\n",
    "print('---df.loc[1,]----')\n",
    "print(df.loc[1,])\n",
    "\n",
    "print('---df.loc[[1,2],]----')\n",
    "print(df.loc[[1,2],])\n",
    "\n",
    "print('---df.loc[1:3]----')\n",
    "print(df.loc[1:3,])\n",
    "\n",
    "# iloc 取行\n",
    "print('---df.iloc[1,]----')\n",
    "print(df.iloc[1,])\n",
    "print('---df.iloc[1:2,]----')\n",
    "print(df.iloc[1:2,])\n",
    "\n",
    "# 取列\n",
    "print('---df.iloc[,1:2]----')\n",
    "df.iloc[:,['1','2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填充值\n",
    "- `df.fillna()`, 填充所有缺失的数据, 可以指定值, 或者使用周围值\n",
    "  - 签名: `df.fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs`\n",
    "    - value: scalar, dict, Series, or DataFrame\n",
    "    - method: default None. ffill/bfill: 根据指定的 axis, 将缺失值的前/后一个数据填入. 如 axis=index, 则是按列, 取列的 前/后 一个值.\n",
    "    - inplace: 是否原地替换. default False. 原地替换是指在原 df 操作.\n",
    "  - 示例: `df.fillna({\"attacker_size\":1.0,\"defender_size\":1.0}, inplace=True)`\n",
    "- `df.dropna()`, 删除有缺失值的数据\n",
    "  - 签名: `df.dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)`\n",
    "    - how: any: 只要有缺失值, 就删除 该行/该列(由axis决定). all: 只有所有元素都是缺失值, 才删除该行/该列.\n",
    "    - thresh: 当有 thresh 个缺失值时, 删除该行/该列\n",
    "    - subset: 只判断 subset 指定的 行/列\n",
    "  - 示例: `df.dropna(subset=['name', 'born', 'sex'], thresh=2)` 当 subset 中最少有两列为 NaN, 则删除该行."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换\n",
    "- `to_datetime()` 将列转换为时间类型: `pd.to_datetime(arg,unit=ns,errors=raise,format='%d/%m/%Y')`, 可以将 时间tuple, int/float/string 等值, list|Series 等转换为时间类型\n",
    "  - [API](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html)\n",
    "  - 转换时间戳: `pd.to_datetime(12312)`, 默认单位 纳秒\n",
    "  - 转换索引: `pd.to_datetime(df.index)`. 如原来的index: [0,1,2,..], 转换过后index: ['1970-01-01','1970-01-02',...]\n",
    "  - 转换多列组合: `df=pd.DataFrame({'year': [2015, 2016],'month': [2, 3],'day': [4, 5]}),  pd.to_datetime(df)` 会将每行的值转换为 datetime 类型\n",
    "- 两个Series运算, 只要有一个相应位置为NaN则结果为NaN\n",
    "\n",
    "#### 索引\n",
    "- 将索引转换转换为时间格式: `df.index = pd.to_datetime(df.index)`\n",
    "- `df.reindex(new_index)`, 重建索引, 传入 array-like 的数据即可\n",
    "  - new_index 有如下定义方式\n",
    "    - 自定义数组 `index = ['c1','c2','c3']`\n",
    "    - 时间索引 `date_index = pd.date_range('1/1/2010', periods=6, freq='D')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进阶\n",
    "### 重建数据\n",
    "- 对于时间索引, 重新对dataframe采样\n",
    "  - 签名: `resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0, on=None, level=None)`\n",
    "  - [API DOC](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html#pandas.DataFrame.resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子\n",
    "1. 查询df每一列有多少缺失值."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
